{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJRSCwP2jN60j3fayqJv3Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidarvai/DIPLOMADOLGOZAT-/blob/main/Xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4n-NEUTckiK",
        "outputId": "cc4b204c-1ee8-4d3c-bd2d-f063570db0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# Konfúziós mátrix és metrikák függvényei\n",
        "# -----------------------------\n",
        "def get_custom_confusion_matrix(tumor_type, tn, fp, fn, tp):\n",
        "    if tumor_type == \"Whole Tumor\":\n",
        "        custom_matrix = np.array([[tn, fp, fp, fp],\n",
        "                                  [fn, tp, tp, tp],\n",
        "                                  [fn, tp, tp, tp],\n",
        "                                  [fn, tp, tp, tp]])\n",
        "    elif tumor_type == \"Edema\":\n",
        "        custom_matrix = np.array([[tn, tn, fp, tn],\n",
        "                                  [tn, tn, fp, tn],\n",
        "                                  [fn, fn, tp, fn],\n",
        "                                  [tn, tn, fp, tn]])\n",
        "    elif tumor_type == \"Tumor Core\":\n",
        "        custom_matrix = np.array([[tn, fp, tn, fp],\n",
        "                                  [fn, tp, fn, tp],\n",
        "                                  [tn, fp, tn, fp],\n",
        "                                  [fn, tp, fn, tp]])\n",
        "    elif tumor_type == \"Enhancing Core\":\n",
        "        custom_matrix = np.array([[tn, tn, tn, fp],\n",
        "                                  [tn, tn, tn, fp],\n",
        "                                  [tn, tn, tn, fp],\n",
        "                                  [fn, fn, fn, tp]])\n",
        "    else:\n",
        "        custom_matrix = None\n",
        "    return custom_matrix\n",
        "\n",
        "def compute_confusion(gt_mask, pred_mask):\n",
        "    tn = np.sum((gt_mask==False) & (pred_mask==False))\n",
        "    tp = np.sum((gt_mask==True)  & (pred_mask==True))\n",
        "    fp = np.sum((gt_mask==False) & (pred_mask==True))\n",
        "    fn = np.sum((gt_mask==True)  & (pred_mask==False))\n",
        "    return tn, fp, fn, tp\n",
        "\n",
        "def compute_metrics(tn, fp, fn, tp):\n",
        "    TPR = tp / (tp + fn) if (tp+fn) > 0 else 0\n",
        "    TNR = tn / (tn + fp) if (tn+fp) > 0 else 0\n",
        "    PPV = tp / (tp + fp) if (tp+fp) > 0 else 0\n",
        "    NPV = tn / (tn + fn) if (tn+fn) > 0 else 0\n",
        "    ACC = (tp + tn) / (tp + tn + fp + fn) if (tp+tn+fp+fn)>0 else 0\n",
        "    DS  = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn)>0 else 0\n",
        "    return TPR, TNR, PPV, NPV, ACC, DS\n",
        "\n",
        "# -----------------------------\n",
        "# Adat betöltés és előfeldolgozás\n",
        "# -----------------------------\n",
        "def remap_segmentation(seg):\n",
        "    seg_new = np.copy(seg)\n",
        "    # Az eredeti adatokban a label 4 az enhancing core, amit átmappolunk 3-ra\n",
        "    seg_new[seg == 4] = 3\n",
        "    return seg_new\n",
        "\n",
        "def load_subject_data(subject_path):\n",
        "    files = os.listdir(subject_path)\n",
        "    subject_data = {}\n",
        "    for file in files:\n",
        "        if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
        "            lower = file.lower()\n",
        "            if 'seg' in lower:\n",
        "                subject_data['seg'] = os.path.join(subject_path, file)\n",
        "            else:\n",
        "                for mod in ['t1', 't1ce', 't2', 'flair']:\n",
        "                    if mod in lower:\n",
        "                        subject_data[mod] = os.path.join(subject_path, file)\n",
        "    return subject_data\n",
        "\n",
        "def load_data_from_dir(data_dir):\n",
        "    X_list = []  # 3D volume (H,W,D,4)\n",
        "    Y_list = []  # 3D segmentation (H,W,D)\n",
        "    subject_names = []\n",
        "    subject_dirs = [os.path.join(data_dir, d) for d in os.listdir(data_dir)\n",
        "                    if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    subject_dirs.sort()\n",
        "    for subject_path in subject_dirs:\n",
        "        data_files = load_subject_data(subject_path)\n",
        "        if all(mod in data_files for mod in ['t1', 't1ce', 't2', 'flair']) and 'seg' in data_files:\n",
        "            modality_imgs = []\n",
        "            for mod in ['t1', 't1ce', 't2', 'flair']:\n",
        "                img = nib.load(data_files[mod]).get_fdata()\n",
        "                modality_imgs.append(img)\n",
        "            X = np.stack(modality_imgs, axis=-1)  # shape: (H,W,D,4)\n",
        "            seg = nib.load(data_files['seg']).get_fdata()\n",
        "            seg = remap_segmentation(seg)\n",
        "            X_list.append(X)\n",
        "            Y_list.append(seg)\n",
        "            subject_names.append(os.path.basename(subject_path))\n",
        "        else:\n",
        "            print(\"Hiányos adatok:\", subject_path)\n",
        "    return X_list, Y_list, subject_names\n",
        "\n",
        "def normalize_volume(vol):\n",
        "    vol = vol.astype(np.float32)\n",
        "    vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1e-8)\n",
        "    return vol\n",
        "\n",
        "# -----------------------------\n",
        "# Szeletek kinyerése (2D) – hasonló logika, mint a CNN esetében\n",
        "# -----------------------------\n",
        "def extract_slices(volume, seg, slice_axis=2, include_bg_ratio=0.3):\n",
        "    slices_x = []\n",
        "    slices_y = []\n",
        "    D = volume.shape[slice_axis]\n",
        "    for i in range(D):\n",
        "        img_slice = volume[:, :, i, :]  # (H, W, 4)\n",
        "        seg_slice = seg[:, :, i]         # (H, W)\n",
        "        # Ha a szeletben van tumor, vagy véletlenszerűen választunk háttér szeletet\n",
        "        if np.sum(seg_slice > 0) > 0.01 * (seg_slice.shape[0] * seg_slice.shape[1]):\n",
        "            slices_x.append(img_slice)\n",
        "            slices_y.append(seg_slice)\n",
        "        else:\n",
        "            if np.random.rand() < include_bg_ratio:\n",
        "                slices_x.append(img_slice)\n",
        "                slices_y.append(seg_slice)\n",
        "    return slices_x, slices_y\n",
        "\n",
        "# -----------------------------\n",
        "# Pixel mintavételezés egy szeletből\n",
        "# -----------------------------\n",
        "def sample_pixels_from_slice(img_slice, seg_slice, num_samples=1000, tumor_ratio=0.5):\n",
        "    H, W, C = img_slice.shape  # C=4\n",
        "    # Lekérjük az indexeket\n",
        "    tumor_idx = np.argwhere(seg_slice > 0)\n",
        "    bg_idx = np.argwhere(seg_slice == 0)\n",
        "\n",
        "    n_tumor = int(num_samples * tumor_ratio)\n",
        "    n_bg = num_samples - n_tumor\n",
        "\n",
        "    # Ha túl kevés tumor pixel van, vegyük az összeset\n",
        "    if len(tumor_idx) < n_tumor:\n",
        "        tumor_sample = tumor_idx\n",
        "        n_bg = num_samples - len(tumor_sample)\n",
        "    else:\n",
        "        indices = np.random.choice(len(tumor_idx), n_tumor, replace=False)\n",
        "        tumor_sample = tumor_idx[indices]\n",
        "\n",
        "    if len(bg_idx) < n_bg:\n",
        "        bg_sample = bg_idx\n",
        "    else:\n",
        "        indices = np.random.choice(len(bg_idx), n_bg, replace=False)\n",
        "        bg_sample = bg_idx[indices]\n",
        "\n",
        "    # Egyesítjük a mintákat\n",
        "    all_idx = np.concatenate([tumor_sample, bg_sample], axis=0)\n",
        "    # Véletlen sorrendbe keverjük az indexeket\n",
        "    np.random.shuffle(all_idx)\n",
        "\n",
        "    # Kinyerjük a jellemzőket és a címkéket\n",
        "    features = []\n",
        "    labels = []\n",
        "    for idx in all_idx:\n",
        "        i, j = idx\n",
        "        features.append(img_slice[i, j, :])\n",
        "        labels.append(int(seg_slice[i, j]))\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# -----------------------------\n",
        "# Tréning adathalmaz előállítása pixel szinten\n",
        "# -----------------------------\n",
        "def create_training_dataset(volumes, segmentations, num_samples_per_slice=1000):\n",
        "    X_samples = []\n",
        "    y_samples = []\n",
        "    for vol, seg in zip(volumes, segmentations):\n",
        "        slices_img, slices_seg = extract_slices(vol, seg, slice_axis=2, include_bg_ratio=0.3)\n",
        "        for img_slice, seg_slice in zip(slices_img, slices_seg):\n",
        "            # Ha a szelet túl kicsi, kihagyjuk\n",
        "            if img_slice.shape[0] < 10 or img_slice.shape[1] < 10:\n",
        "                continue\n",
        "            Xp, yp = sample_pixels_from_slice(img_slice, seg_slice, num_samples=num_samples_per_slice, tumor_ratio=0.5)\n",
        "            X_samples.append(Xp)\n",
        "            y_samples.append(yp)\n",
        "    if len(X_samples) == 0:\n",
        "        raise ValueError(\"Nincsenek érvényes szelet minták!\")\n",
        "    X_all = np.concatenate(X_samples, axis=0)\n",
        "    y_all = np.concatenate(y_samples, axis=0)\n",
        "    return X_all, y_all\n",
        "\n",
        "# -----------------------------\n",
        "# Teszt adatoknál a teljes szelet előrejelzésének függvénye\n",
        "# -----------------------------\n",
        "def predict_volume(model, volume):\n",
        "    H, W, D, _ = volume.shape\n",
        "    pred_vol = np.zeros((H, W, D), dtype=np.int32)\n",
        "    for i in range(D):\n",
        "        x_slice = volume[:, :, i, :]  # (H, W, 4)\n",
        "        # Flatten a szeletet: (H*W, 4)\n",
        "        x_flat = x_slice.reshape(-1, x_slice.shape[-1])\n",
        "        # Model előrejelzés\n",
        "        pred_flat = model.predict(x_flat)\n",
        "        pred_slice = pred_flat.reshape(H, W)\n",
        "        pred_vol[:, :, i] = pred_slice\n",
        "    return pred_vol\n",
        "\n",
        "# -----------------------------\n",
        "# A kapott 3D eredmény bináris maszkra konvertálása a tumor típus alapján\n",
        "# -----------------------------\n",
        "def get_binary_mask_3d(segmentation, tumor_type):\n",
        "    if tumor_type == \"Whole Tumor\":\n",
        "        return np.isin(segmentation, [1,2,3])\n",
        "    elif tumor_type == \"Edema\":\n",
        "        return (segmentation == 2)\n",
        "    elif tumor_type == \"Tumor Core\":\n",
        "        return np.isin(segmentation, [1,3])\n",
        "    elif tumor_type == \"Enhancing Core\":\n",
        "        return (segmentation == 3)\n",
        "    else:\n",
        "        raise ValueError(\"Ismeretlen tumor típus!\")\n",
        "\n",
        "# -----------------------------\n",
        "# Fő program\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Állítsd be az útvonalakat\n",
        "    train_dir = \"/content/drive/My Drive/Allamvizsga/Data/Teszt/Train\"\n",
        "    test_dir  = \"/content/drive/My Drive/Allamvizsga/Data/Teszt/Teszt\"\n",
        "\n",
        "    print(\"Train adatok betöltése...\")\n",
        "    X_train_vols, Y_train_vols, train_subject_names = load_data_from_dir(train_dir)\n",
        "    if len(X_train_vols) == 0:\n",
        "        raise ValueError(\"Nincsenek betöltött train adatok!\")\n",
        "    X_train_vols = [normalize_volume(vol) for vol in X_train_vols]\n",
        "\n",
        "    print(\"Tréning pixel adatok előállítása...\")\n",
        "    X_pixels, y_pixels = create_training_dataset(X_train_vols, Y_train_vols, num_samples_per_slice=1000)\n",
        "    print(\"Összes minta:\", X_pixels.shape, y_pixels.shape)\n",
        "\n",
        "    # Train/Validation split (pixel szinten)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_pixels, y_pixels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # XGBoost osztályozó – 4 osztály (0,1,2,3)\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=4,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='mlogloss',\n",
        "        verbosity=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(\"XGBoost tréning...\")\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Tesztelés: A teljes 3D térkép előrejelzése szeletenként\n",
        "    # -----------------------------\n",
        "    print(\"Teszt adatok betöltése...\")\n",
        "    X_test_vols, Y_test_vols, test_subject_names = load_data_from_dir(test_dir)\n",
        "    if len(X_test_vols) == 0:\n",
        "        raise ValueError(\"Nincsenek betöltött teszt adatok!\")\n",
        "    X_test_vols = [normalize_volume(vol) for vol in X_test_vols]\n",
        "\n",
        "    metrics_rows = []\n",
        "    output_txt_lines = []\n",
        "    tumor_types = [\"Whole Tumor\", \"Edema\", \"Tumor Core\", \"Enhancing Core\"]\n",
        "\n",
        "    for vol, seg, subj_name in zip(X_test_vols, Y_test_vols, test_subject_names):\n",
        "        print(\"Előrejelzés a\", subj_name, \"subjectön...\")\n",
        "        pred_vol = predict_volume(model, vol)\n",
        "\n",
        "        # Metrikák számítása minden tumor típusra\n",
        "        for tumor in tumor_types:\n",
        "            gt_mask = get_binary_mask_3d(seg, tumor)\n",
        "            pred_mask = get_binary_mask_3d(pred_vol, tumor)\n",
        "            tn, fp, fn, tp = compute_confusion(gt_mask, pred_mask)\n",
        "            TPR, TNR, PPV, NPV, ACC, DS = compute_metrics(tn, fp, fn, tp)\n",
        "            cm = get_custom_confusion_matrix(tumor, tn, fp, fn, tp)\n",
        "\n",
        "            metrics_rows.append({\n",
        "                \"Name\": subj_name,\n",
        "                \"TumorType\": tumor,\n",
        "                \"TP\": tp,\n",
        "                \"TN\": tn,\n",
        "                \"FP\": fp,\n",
        "                \"FN\": fn,\n",
        "                \"TPR\": round(TPR, 3),\n",
        "                \"TNR\": round(TNR, 3),\n",
        "                \"PPV\": round(PPV, 3),\n",
        "                \"NPV\": round(NPV, 3),\n",
        "                \"ACC\": round(ACC, 3),\n",
        "                \"DS\": round(DS, 3)\n",
        "            })\n",
        "\n",
        "            txt_block = f\"Mapa neve: {subj_name}\\nTumor típus: {tumor}\\nKonfúziós mátrix:\\n{cm}\\n\"\n",
        "            txt_block += f\"True Positive Rate (TPR): {round(TPR,3)}\\n\"\n",
        "            txt_block += f\"True Negative Rate (TNR): {round(TNR,3)}\\n\"\n",
        "            txt_block += f\"Positive Predictive Value (PPV): {round(PPV,3)}\\n\"\n",
        "            txt_block += f\"Negative Predictive Value (NPV): {round(NPV,3)}\\n\"\n",
        "            txt_block += f\"Accuracy (ACC): {round(ACC,3)}\\n\"\n",
        "            txt_block += f\"Dice Score (DS): {round(DS,3)}\\n\\n\"\n",
        "            output_txt_lines.append(txt_block)\n",
        "\n",
        "    # Eredmények mentése CSV-be\n",
        "    metrics_df = pd.DataFrame(metrics_rows, columns=[\"Name\", \"TumorType\", \"TP\", \"TN\", \"FP\", \"FN\", \"TPR\", \"TNR\", \"PPV\", \"NPV\", \"ACC\", \"DS\"])\n",
        "    metrics_df.to_csv(\"metrics_output.csv\", index=False)\n",
        "    print(\"A metrics_output.csv fájl elmentve.\")\n",
        "\n",
        "    # Eredmények mentése TXT-be\n",
        "    with open(\"output.txt\", \"w\") as f:\n",
        "        f.write(\"\".join(output_txt_lines))\n",
        "    print(\"Az output.txt fájl elmentve.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0fZ3bCccotB",
        "outputId": "f5bd10e6-b42c-4c40-8910-b7b70bcd1040"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train adatok betöltése...\n",
            "Tréning pixel adatok előállítása...\n",
            "Összes minta: (771000, 4) (771000,)\n",
            "XGBoost tréning...\n",
            "[0]\tvalidation_0-mlogloss:0.94814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:40:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalidation_0-mlogloss:0.72045\n",
            "[2]\tvalidation_0-mlogloss:0.57577\n",
            "[3]\tvalidation_0-mlogloss:0.47606\n",
            "[4]\tvalidation_0-mlogloss:0.40509\n",
            "[5]\tvalidation_0-mlogloss:0.35455\n",
            "[6]\tvalidation_0-mlogloss:0.31755\n",
            "[7]\tvalidation_0-mlogloss:0.28996\n",
            "[8]\tvalidation_0-mlogloss:0.27001\n",
            "[9]\tvalidation_0-mlogloss:0.25491\n",
            "[10]\tvalidation_0-mlogloss:0.24277\n",
            "[11]\tvalidation_0-mlogloss:0.23371\n",
            "[12]\tvalidation_0-mlogloss:0.22641\n",
            "[13]\tvalidation_0-mlogloss:0.22126\n",
            "[14]\tvalidation_0-mlogloss:0.21702\n",
            "[15]\tvalidation_0-mlogloss:0.21367\n",
            "[16]\tvalidation_0-mlogloss:0.21127\n",
            "[17]\tvalidation_0-mlogloss:0.20902\n",
            "[18]\tvalidation_0-mlogloss:0.20702\n",
            "[19]\tvalidation_0-mlogloss:0.20506\n",
            "[20]\tvalidation_0-mlogloss:0.20324\n",
            "[21]\tvalidation_0-mlogloss:0.20238\n",
            "[22]\tvalidation_0-mlogloss:0.20159\n",
            "[23]\tvalidation_0-mlogloss:0.20097\n",
            "[24]\tvalidation_0-mlogloss:0.19978\n",
            "[25]\tvalidation_0-mlogloss:0.19910\n",
            "[26]\tvalidation_0-mlogloss:0.19797\n",
            "[27]\tvalidation_0-mlogloss:0.19708\n",
            "[28]\tvalidation_0-mlogloss:0.19644\n",
            "[29]\tvalidation_0-mlogloss:0.19580\n",
            "[30]\tvalidation_0-mlogloss:0.19508\n",
            "[31]\tvalidation_0-mlogloss:0.19427\n",
            "[32]\tvalidation_0-mlogloss:0.19340\n",
            "[33]\tvalidation_0-mlogloss:0.19274\n",
            "[34]\tvalidation_0-mlogloss:0.19203\n",
            "[35]\tvalidation_0-mlogloss:0.19126\n",
            "[36]\tvalidation_0-mlogloss:0.19093\n",
            "[37]\tvalidation_0-mlogloss:0.18993\n",
            "[38]\tvalidation_0-mlogloss:0.18940\n",
            "[39]\tvalidation_0-mlogloss:0.18887\n",
            "[40]\tvalidation_0-mlogloss:0.18838\n",
            "[41]\tvalidation_0-mlogloss:0.18796\n",
            "[42]\tvalidation_0-mlogloss:0.18754\n",
            "[43]\tvalidation_0-mlogloss:0.18708\n",
            "[44]\tvalidation_0-mlogloss:0.18662\n",
            "[45]\tvalidation_0-mlogloss:0.18630\n",
            "[46]\tvalidation_0-mlogloss:0.18600\n",
            "[47]\tvalidation_0-mlogloss:0.18559\n",
            "[48]\tvalidation_0-mlogloss:0.18544\n",
            "[49]\tvalidation_0-mlogloss:0.18508\n",
            "[50]\tvalidation_0-mlogloss:0.18469\n",
            "[51]\tvalidation_0-mlogloss:0.18437\n",
            "[52]\tvalidation_0-mlogloss:0.18413\n",
            "[53]\tvalidation_0-mlogloss:0.18380\n",
            "[54]\tvalidation_0-mlogloss:0.18355\n",
            "[55]\tvalidation_0-mlogloss:0.18346\n",
            "[56]\tvalidation_0-mlogloss:0.18329\n",
            "[57]\tvalidation_0-mlogloss:0.18311\n",
            "[58]\tvalidation_0-mlogloss:0.18300\n",
            "[59]\tvalidation_0-mlogloss:0.18283\n",
            "[60]\tvalidation_0-mlogloss:0.18248\n",
            "[61]\tvalidation_0-mlogloss:0.18229\n",
            "[62]\tvalidation_0-mlogloss:0.18211\n",
            "[63]\tvalidation_0-mlogloss:0.18176\n",
            "[64]\tvalidation_0-mlogloss:0.18152\n",
            "[65]\tvalidation_0-mlogloss:0.18138\n",
            "[66]\tvalidation_0-mlogloss:0.18124\n",
            "[67]\tvalidation_0-mlogloss:0.18117\n",
            "[68]\tvalidation_0-mlogloss:0.18102\n",
            "[69]\tvalidation_0-mlogloss:0.18076\n",
            "[70]\tvalidation_0-mlogloss:0.18075\n",
            "[71]\tvalidation_0-mlogloss:0.18065\n",
            "[72]\tvalidation_0-mlogloss:0.18056\n",
            "[73]\tvalidation_0-mlogloss:0.18050\n",
            "[74]\tvalidation_0-mlogloss:0.18035\n",
            "[75]\tvalidation_0-mlogloss:0.18026\n",
            "[76]\tvalidation_0-mlogloss:0.18006\n",
            "[77]\tvalidation_0-mlogloss:0.17992\n",
            "[78]\tvalidation_0-mlogloss:0.17980\n",
            "[79]\tvalidation_0-mlogloss:0.17955\n",
            "[80]\tvalidation_0-mlogloss:0.17940\n",
            "[81]\tvalidation_0-mlogloss:0.17927\n",
            "[82]\tvalidation_0-mlogloss:0.17923\n",
            "[83]\tvalidation_0-mlogloss:0.17901\n",
            "[84]\tvalidation_0-mlogloss:0.17874\n",
            "[85]\tvalidation_0-mlogloss:0.17861\n",
            "[86]\tvalidation_0-mlogloss:0.17853\n",
            "[87]\tvalidation_0-mlogloss:0.17841\n",
            "[88]\tvalidation_0-mlogloss:0.17836\n",
            "[89]\tvalidation_0-mlogloss:0.17823\n",
            "[90]\tvalidation_0-mlogloss:0.17817\n",
            "[91]\tvalidation_0-mlogloss:0.17810\n",
            "[92]\tvalidation_0-mlogloss:0.17807\n",
            "[93]\tvalidation_0-mlogloss:0.17798\n",
            "[94]\tvalidation_0-mlogloss:0.17782\n",
            "[95]\tvalidation_0-mlogloss:0.17776\n",
            "[96]\tvalidation_0-mlogloss:0.17773\n",
            "[97]\tvalidation_0-mlogloss:0.17766\n",
            "[98]\tvalidation_0-mlogloss:0.17767\n",
            "[99]\tvalidation_0-mlogloss:0.17766\n",
            "Teszt adatok betöltése...\n",
            "Előrejelzés a BraTS20_Training_005 subjectön...\n",
            "Előrejelzés a BraTS20_Training_055 subjectön...\n",
            "Előrejelzés a BraTS20_Training_083 subjectön...\n",
            "Előrejelzés a BraTS20_Training_108 subjectön...\n",
            "Előrejelzés a BraTS20_Training_118 subjectön...\n",
            "Előrejelzés a BraTS20_Training_132 subjectön...\n",
            "Előrejelzés a BraTS20_Training_147 subjectön...\n",
            "Előrejelzés a BraTS20_Training_151 subjectön...\n",
            "Előrejelzés a BraTS20_Training_340 subjectön...\n",
            "Előrejelzés a BraTS20_Training_369 subjectön...\n",
            "A metrics_output.csv fájl elmentve.\n",
            "Az output.txt fájl elmentve.\n"
          ]
        }
      ]
    }
  ]
}